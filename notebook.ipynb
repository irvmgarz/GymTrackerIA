{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym Exercise Repetition Counter and Classifier\n",
    "## Introducción\n",
    "El objetivo de este proyecto es desarrollar un modelo de Machine Learning que permita contar repeticiones y predecir el tipo de ejercicio realizado en el gimnasio en tiempo real. Los datos provienen de sensores de acelerómetro y giroscopio integrados en un smartwatch. Esto busca mejorar la experiencia del usuario, optimizar el entrenamiento y reducir el riesgo de lesiones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación de datos\n",
    "\n",
    "### Importación de bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from scipy.signal import butter, lfilter, filtfilt\n",
    "from scipy.special import erf\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga y exploración inicial de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset en formato Pickle\n",
    "raw_data = pd.read_pickle(\"src/data/01_Data_Processed.pkl\")\n",
    "print(\"Primeras filas del dataset:\")\n",
    "print(raw_data.head())\n",
    "# Información general del dataset\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detección y tratamiento de outliers\n",
    "### Métodos de detección de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_outliers_iqr(dataset, col):\n",
    "    Q1 = dataset[col].quantile(0.25)\n",
    "    Q3 = dataset[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    dataset[col + \"_outlier\"] = (dataset[col] < lower_bound) | (dataset[col] > upper_bound)\n",
    "    return dataset\n",
    "\n",
    "def mark_outliers_chauvenet(dataset, col, C=2):\n",
    "    mean = dataset[col].mean()\n",
    "    std = dataset[col].std()\n",
    "    N = len(dataset.index)\n",
    "    criterion = 1.0 / (C * N)\n",
    "\n",
    "    deviation = abs(dataset[col] - mean) / std\n",
    "\n",
    "    prob = 1.0 - 0.5 * (erf(deviation / np.sqrt(2)) - erf(-deviation / np.sqrt(2)))\n",
    "    dataset[col + \"_outlier\"] = prob < criterion\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_columns = raw_data.columns[1:7]\n",
    "outliers_removed = raw_data.copy()\n",
    "\n",
    "for col in outlier_columns:\n",
    "    for label in raw_data[\"Label\"].unique():\n",
    "        subset = mark_outliers_chauvenet(raw_data[raw_data[\"Label\"] == label], col)\n",
    "        subset.loc[subset[col + \"_outlier\"], col] = np.nan\n",
    "        outliers_removed.update(subset)\n",
    "\n",
    "# Guardar el dataset sin outliers\n",
    "outliers_removed.to_pickle(\"../data/02_outliers_removed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generación de características (Feature Engineering)\n",
    "\n",
    "### Transformaciones temporales y de frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de la transformación de Fourier y abstracciones temporales\n",
    "def fourier_transformation(data, col, window_size, sampling_rate):\n",
    "    freqs = np.fft.rfftfreq(window_size, 1 / sampling_rate)\n",
    "    fft_values = np.fft.rfft(data[col])\n",
    "    return freqs, abs(fft_values)\n",
    "\n",
    "def temporal_abstraction(data, cols, window_size, aggregation):\n",
    "    for col in cols:\n",
    "        data[col + f\"_{aggregation}_ws{window_size}\"] = data[col].rolling(window_size).aggregate(aggregation)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de características combinadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear características adicionales\n",
    "processed_data = pd.read_pickle(\"../data/02_outliers_removed.pkl\")\n",
    "processed_data[\"acc_r\"] = np.sqrt(\n",
    "    processed_data[\"Accelerometer_x\"] ** 2 + \n",
    "    processed_data[\"Accelerometer_y\"] ** 2 + \n",
    "    processed_data[\"Accelerometer_z\"] ** 2\n",
    ")\n",
    "\n",
    "# Aplicar abstracciones temporales\n",
    "processed_data = temporal_abstraction(processed_data, [\"acc_r\"], window_size=5, aggregation=\"mean\")\n",
    "\n",
    "# Guardar el dataset con nuevas características\n",
    "processed_data.to_pickle(\"../data/03_data_features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento y evaluación de modelos\n",
    "\n",
    "### División de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"../data/03_data_features.pkl\")\n",
    "X = data.drop([\"Label\", \"Participants\", \"Set\"], axis=1)\n",
    "y = data[\"Label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar clasificadores\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"Red Neuronal\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500),\n",
    "    \"SVM\": SVC(kernel=\"rbf\", probability=True),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[model_name] = accuracy\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar resultados\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(results.keys(), results.values())\n",
    "plt.title(\"Comparación de Precisión entre Modelos\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusión\n",
    "\n",
    "1. **Resumen**: Evaluamos múltiples modelos de clasificación y obtuvimos el mejor rendimiento con `Random Forest`.\n",
    "2. **Aplicaciones**: Este sistema permite contar repeticiones y clasificar ejercicios en tiempo real, optimizando entrenamientos.\n",
    "3. **Trabajo futuro**: Integrar el modelo en una aplicación móvil o smartwatch para uso en tiempo real.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
